{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bcc74ea",
   "metadata": {},
   "source": [
    "# Model Selection for Reliability Testing\n",
    "\n",
    "**Method**\n",
    "\n",
    "- Deductively coded table turned into a prompt. AI will be used to code the dataset. See `INTERACTION_PROMPT_TEMPLATEv3`\n",
    "- Random sample of 50 chat sessions taken from the dataset\n",
    "- Human (that's me) coded the 50 chat sessions\n",
    "- Each model will code the same 50 chat sessions three times to test for internal consistency\n",
    "\n",
    "### Which model to select?\n",
    "\n",
    "- Models compared, as rater / annotator:\n",
    "\n",
    "    - Human\n",
    "    - \"x-ai/grok-4-fast\"\n",
    "    - \"openai/gpt-5-mini\"\n",
    "    - \"google/gemini-2.5-flash\"\n",
    "    - \"anthropic/claude-sonnet-4\"\n",
    "    \n",
    " - Krippendorff's alpha \n",
    "    \n",
    "    - for human / ai model agreement ... which model was highest?\n",
    "    - interal consistency among multiple runs of the same LLM (3 passes on the same model) ... which was most consistent?\n",
    "\n",
    "\n",
    "Selection of LLM to code the entire session dataset (N=1024), based on highest agreement with human coding and highest internal consistency.\n",
    "\n",
    " - Target for LLM / Human agreement: (target Krippendorff's alpha >= 0.85)\n",
    " - Target for internal consistency: (target Krippendorff's alpha = 1.0)\n",
    "\n",
    "### Findings\n",
    "\n",
    "Best model:\n",
    "\n",
    "- \"anthropic/claude-sonnet-4\"\n",
    "    - Agreement with human: 0.873131\n",
    "    - Internal consistency: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e8d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TABLEAU_COLORS\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import simpledorff\n",
    "import json\n",
    "import import_ipynb\n",
    "from llm_content_analysis import invoke_openrouter_ai, INTERACTION_PROMPT_TEMPLATEv3, classify_interaction\n",
    "from helper_functions import independent_ttest\n",
    "\n",
    "NUM_ITERATIONS = 3\n",
    "SAMPLES = [\n",
    "    {\"model\": \"x-ai/grok-4-fast\" }, \n",
    "    {\"model\": \"openai/gpt-5-mini\"},\n",
    "    {\"model\": \"google/gemini-2.5-flash\" },\n",
    "    {\"model\": \"anthropic/claude-sonnet-4\" }\n",
    "]\n",
    "\n",
    "model_comparison_df = pd.DataFrame( { 'model': [sample['model'] for sample in SAMPLES]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805e97ef",
   "metadata": {},
   "source": [
    "### Dataset for Analysis:\n",
    "\n",
    "- `50_sample_4_llm_3_iterations_labels.csv` - 50 samples coded 3 times by 4 different LLMs for a total of 600 rows\n",
    "- `50_sample_human_labels.csv` - 50 samples coded by human for a total of 50 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f010a5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_number</th>\n",
       "      <th>participant</th>\n",
       "      <th>sessionid</th>\n",
       "      <th>message_count</th>\n",
       "      <th>transcript_filename</th>\n",
       "      <th>transcript</th>\n",
       "      <th>classification</th>\n",
       "      <th>justification</th>\n",
       "      <th>model</th>\n",
       "      <th>sample</th>\n",
       "      <th>behavior_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>Participant_17</td>\n",
       "      <td>4151274b-0515-4308-984e-7af035baefa4</td>\n",
       "      <td>2</td>\n",
       "      <td>Participant_17_session_4151274b-0515-4308-984e...</td>\n",
       "      <td>PARTICIPANT_17:\\nwhat files need to be in the ...</td>\n",
       "      <td>Task Completion</td>\n",
       "      <td>{'behavior_code': 'Seeking Answers', 'rational...</td>\n",
       "      <td>x-ai/grok-4-fast</td>\n",
       "      <td>1</td>\n",
       "      <td>Seeking Answers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>Participant_64</td>\n",
       "      <td>ebde0db7-fa59-4e38-9b9f-a1c15db8f474</td>\n",
       "      <td>2</td>\n",
       "      <td>Participant_64_session_ebde0db7-fa59-4e38-9b9f...</td>\n",
       "      <td>PARTICIPANT_64:\\ncan you explain parse to me\\n...</td>\n",
       "      <td>Learning</td>\n",
       "      <td>{'behavior_code': 'Questioning', 'rationale': ...</td>\n",
       "      <td>x-ai/grok-4-fast</td>\n",
       "      <td>1</td>\n",
       "      <td>Questioning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>Participant_41</td>\n",
       "      <td>6b8bc12d-8642-494c-b278-04b79ef1f968</td>\n",
       "      <td>9</td>\n",
       "      <td>Participant_41_session_6b8bc12d-8642-494c-b278...</td>\n",
       "      <td>PARTICIPANT_41:\\nis my 1.3 code correct?\\n\\nAI...</td>\n",
       "      <td>Learning</td>\n",
       "      <td>{'behavior_code': 'Scaffolding', 'rationale': ...</td>\n",
       "      <td>x-ai/grok-4-fast</td>\n",
       "      <td>1</td>\n",
       "      <td>Scaffolding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>Participant_49</td>\n",
       "      <td>32ea3ad9-099a-4dac-891c-22d2db740102</td>\n",
       "      <td>2</td>\n",
       "      <td>Participant_49_session_32ea3ad9-099a-4dac-891c...</td>\n",
       "      <td>PARTICIPANT_49:\\nwhat does sort() do?\\n\\nAI_AS...</td>\n",
       "      <td>Learning</td>\n",
       "      <td>{'behavior_code': 'Questioning', 'rationale': ...</td>\n",
       "      <td>x-ai/grok-4-fast</td>\n",
       "      <td>1</td>\n",
       "      <td>Questioning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Participant_36</td>\n",
       "      <td>82bcaae3-22da-4174-b181-c56edffdb305</td>\n",
       "      <td>4</td>\n",
       "      <td>Participant_36_session_82bcaae3-22da-4174-b181...</td>\n",
       "      <td>PARTICIPANT_36:\\nwhat does x.upper or x.lower ...</td>\n",
       "      <td>Learning</td>\n",
       "      <td>{'behavior_code': 'Questioning', 'rationale': ...</td>\n",
       "      <td>x-ai/grok-4-fast</td>\n",
       "      <td>1</td>\n",
       "      <td>Questioning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_number     participant                             sessionid  \\\n",
       "0                  17  Participant_17  4151274b-0515-4308-984e-7af035baefa4   \n",
       "1                  64  Participant_64  ebde0db7-fa59-4e38-9b9f-a1c15db8f474   \n",
       "2                  41  Participant_41  6b8bc12d-8642-494c-b278-04b79ef1f968   \n",
       "3                  49  Participant_49  32ea3ad9-099a-4dac-891c-22d2db740102   \n",
       "4                  36  Participant_36  82bcaae3-22da-4174-b181-c56edffdb305   \n",
       "\n",
       "   message_count                                transcript_filename  \\\n",
       "0              2  Participant_17_session_4151274b-0515-4308-984e...   \n",
       "1              2  Participant_64_session_ebde0db7-fa59-4e38-9b9f...   \n",
       "2              9  Participant_41_session_6b8bc12d-8642-494c-b278...   \n",
       "3              2  Participant_49_session_32ea3ad9-099a-4dac-891c...   \n",
       "4              4  Participant_36_session_82bcaae3-22da-4174-b181...   \n",
       "\n",
       "                                          transcript   classification  \\\n",
       "0  PARTICIPANT_17:\\nwhat files need to be in the ...  Task Completion   \n",
       "1  PARTICIPANT_64:\\ncan you explain parse to me\\n...         Learning   \n",
       "2  PARTICIPANT_41:\\nis my 1.3 code correct?\\n\\nAI...         Learning   \n",
       "3  PARTICIPANT_49:\\nwhat does sort() do?\\n\\nAI_AS...         Learning   \n",
       "4  PARTICIPANT_36:\\nwhat does x.upper or x.lower ...         Learning   \n",
       "\n",
       "                                       justification             model  \\\n",
       "0  {'behavior_code': 'Seeking Answers', 'rational...  x-ai/grok-4-fast   \n",
       "1  {'behavior_code': 'Questioning', 'rationale': ...  x-ai/grok-4-fast   \n",
       "2  {'behavior_code': 'Scaffolding', 'rationale': ...  x-ai/grok-4-fast   \n",
       "3  {'behavior_code': 'Questioning', 'rationale': ...  x-ai/grok-4-fast   \n",
       "4  {'behavior_code': 'Questioning', 'rationale': ...  x-ai/grok-4-fast   \n",
       "\n",
       "   sample    behavior_code  \n",
       "0       1  Seeking Answers  \n",
       "1       1      Questioning  \n",
       "2       1      Scaffolding  \n",
       "3       1      Questioning  \n",
       "4       1      Questioning  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_labels = pd.read_csv(\"../datasets/50_sample_4_llm_3_iterations_labels.csv\")\n",
    "human_labels = pd.read_csv(\"../datasets/50_sample_human_labels.csv\")\n",
    "llm_labels.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93316304",
   "metadata": {},
   "source": [
    "## Inter-rater reliability of the LLM vs Human\n",
    "\n",
    "Let's compare the human coding (my coding) with the LLM coding using Krippendorff's alpha to find the most \"mike-like\" LLM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a30ae68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-rater reliability (Krippendorff's alpha) of LLMs vs Human Threshold: 0.85\n",
      "Iteration 1\n",
      "\t✅x-ai/grok-4-fast vs human ==> 0.8731311405382315\n",
      "\t❌openai/gpt-5-mini vs human ==> 0.7885519008970525\n",
      "\t❌google/gemini-2.5-flash vs human ==> 0.8330522765598651\n",
      "\t✅anthropic/claude-sonnet-4 vs human ==> 0.8731311405382315\n",
      "Iteration 2\n",
      "\t✅x-ai/grok-4-fast vs human ==> 0.8693356797184337\n",
      "\t❌openai/gpt-5-mini vs human ==> 0.7495784148397977\n",
      "\t❌google/gemini-2.5-flash vs human ==> 0.8330522765598651\n",
      "\t✅anthropic/claude-sonnet-4 vs human ==> 0.8731311405382315\n",
      "Iteration 3\n",
      "\t✅x-ai/grok-4-fast vs human ==> 0.8764044943820225\n",
      "\t❌openai/gpt-5-mini vs human ==> 0.7885519008970525\n",
      "\t❌google/gemini-2.5-flash vs human ==> 0.8330522765598651\n",
      "\t✅anthropic/claude-sonnet-4 vs human ==> 0.8731311405382315\n"
     ]
    }
   ],
   "source": [
    "print(\"Inter-rater reliability (Krippendorff's alpha) of LLMs vs Human Threshold: 0.85\")\n",
    "# for each iteration\n",
    "for i in range(NUM_ITERATIONS):\n",
    "    # combine humna and llm labels for that iteration\n",
    "    krip = llm_labels[['sessionid','model','classification']][(llm_labels['sample']==i+1)]\n",
    "    krip = pd.concat([krip, human_labels], ignore_index=True)\n",
    "    print(f\"Iteration {i+1}\")\n",
    "    # for each model excluding  human and calculate alpha\n",
    "    for m in krip['model'].unique():\n",
    "        if m == 'human':\n",
    "            continue\n",
    "        comp = krip[krip['model'].isin([m, 'human'])]\n",
    "        alpha = simpledorff.calculate_krippendorffs_alpha_for_df(\n",
    "            comp,\n",
    "            experiment_col='sessionid',\n",
    "            annotator_col='model',\n",
    "            class_col='classification'\n",
    "        )\n",
    "        TARGET_ALPHA = \"✅\" if alpha >= 0.85 else \"❌\"\n",
    "        print(f\"\\t{TARGET_ALPHA}{m} vs human ==> {alpha}\")\n",
    "        model_comparison_df.loc[model_comparison_df['model']==m, 'agreement_with_human'] = alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315b4a15",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d3ede6a",
   "metadata": {},
   "source": [
    "## Internal consistency of the LLMs\n",
    "\n",
    "For internal consistency: (target Krippendorff's alpha = 1.0)\n",
    "\n",
    "Against 3 iterations of the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09f14ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Internal consistency (Krippendorff's alpha) of LLMs Threshold: 1.0\n",
      "\t❌ x-ai/grok-4-fast Krippendorff's Alpha (n=3) ==> 0.8850308641975309\n",
      "\t❌ openai/gpt-5-mini Krippendorff's Alpha (n=3) ==> 0.9147434674804501\n",
      "\t✅ google/gemini-2.5-flash Krippendorff's Alpha (n=3) ==> 1.0\n",
      "\t✅ anthropic/claude-sonnet-4 Krippendorff's Alpha (n=3) ==> 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInternal consistency (Krippendorff's alpha) of LLMs Threshold: 1.0\")\n",
    "for model in llm_labels['model'].unique():\n",
    "    krip = llm_labels[llm_labels['model']==model]\n",
    "    alpha = simpledorff.calculate_krippendorffs_alpha_for_df(\n",
    "        krip,\n",
    "        experiment_col='sessionid',\n",
    "        annotator_col='sample',\n",
    "        class_col='classification'\n",
    "    )\n",
    "    TARGET_ALPHA = \"✅\" if alpha == 1.0 else \"❌\"\n",
    "    print(f\"\\t{TARGET_ALPHA} {model} Krippendorff's Alpha (n=3) ==> {alpha}\")\n",
    "    model_comparison_df.loc[model_comparison_df['model']==model, 'internal_consistency'] = alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529ca589",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Among the models with internal consistency (1.0),  \n",
    "the model with the Highest agreement with human coding was: \n",
    "\n",
    "\"anthropic/claude-sonnet-4\" (0.873131)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14ecaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c6e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a6cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c6f78b3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
